{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "13I61XXlTq5K93lC90_iBKro82nSfIrqH",
      "authorship_tag": "ABX9TyNs6BlzaB5uB3IbEZoyqCE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwhite25/MSG-CcGAN/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIH_ZbgqpJa2"
      },
      "source": [
        "'''\n",
        "main executable for GAN. \n",
        "\n",
        "eventually this will be replaced with another program that pulls and stores data \n",
        "from .h5 files as time series data, then runs the GAN on it. this version is simply\n",
        "for using with images, to test the main implementation of MSG-GAN.\n",
        "\n",
        "Just about everything should be included inside the GAN class, so here we really\n",
        "just need to define some main vars, do some imports, and call the class. \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBaQ_JmSIibW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zkZcoC7M9oj"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/GWPAC/MSG-cGAN/Ours/classes')\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeIOqnP3qe2R"
      },
      "source": [
        "import tensorflow as tf \n",
        "import dataset as ds\n",
        "import msggan as gan\n",
        "from pathlib import Path\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocbg1t1JrfK9"
      },
      "source": [
        "# define some variables/argumens to be used elsewhere \n",
        "# (some of these might be put inside the class rather than here)\n",
        "\n",
        "def main():\n",
        "    loadweights = True\n",
        "    usebias     = False\n",
        "    nrns        = 64\n",
        "    glr         = 1e-2\n",
        "    dlr         = 1e-2\n",
        "    r1g         = 1e-1\n",
        "    epsln       = 1e-3\n",
        "    res         = 8192\n",
        "    bsize       = 32\n",
        "    ksize       = 9\n",
        "\n",
        "    pathway = 'drive/MyDrive/GWPAC/MSG-cGAN/Ours/ins/time_series/has_postmergers/sims'\n",
        "    metadat = 'drive/MyDrive/GWPAC/MSG-cGAN/Ours/ins/time_series/has_postmergers/METADATA.csv'\n",
        "    outpath = f'drive/MyDrive/GWPAC/MSG-cGAN/Ours/outs/tseq_{res}d_{nrns}n_{glr}_{dlr}_{r1g}r_{epsln}e_{ksize}k_c'\n",
        "    weights = f'drive/MyDrive/GWPAC/MSG-cGAN/Ours/outs/tseq_{res}d_{nrns}n_{glr}_{dlr}_{r1g}r_{epsln}e_{ksize}k_b/weights'\n",
        "    \n",
        "    Path(outpath).mkdir(exist_ok=True)\n",
        "    with open(outpath + '/attrs.csv', 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['loadweights', loadweights])\n",
        "        writer.writerow(['neurons', nrns])\n",
        "        writer.writerow(['g learning rate', glr])\n",
        "        writer.writerow(['d learning rate', dlr])\n",
        "        writer.writerow(['r1gamma', r1g])\n",
        "        writer.writerow(['epsilon', epsln])\n",
        "        writer.writerow(['resolution', res])\n",
        "        writer.writerow(['batch size', bsize])\n",
        "\n",
        "    # load the dataset\n",
        "    dataset = ds.Dataset(batch_size=bsize, pathway=pathway, mdpath=metadat, outpath=outpath, nlabels=4, endres=res)\n",
        "    # call the GAN class\n",
        "    # msgg = gan.MSG_GAN_ts(neurs=nrns, endres=dataset.endres, g_lr=glr, d_lr=dlr, r1_gamma=r1g, epsilon=epsln, \n",
        "    #                       outpath=outpath, epochs=500000, nchannels=2, ksize=ksize, usebias=usebias)\n",
        "    msgg = gan.MSG_CcGAN_ts(neurs=nrns, endres=dataset.endres, g_lr=glr, d_lr=dlr, r1_gamma=r1g, epsilon=epsln, \n",
        "                            outpath=outpath, epochs=500000, nchannels=2, ksize=ksize, usebias=usebias)\n",
        "    # continue from previous save point?\n",
        "    if loadweights == True:\n",
        "        msgg.D.load_weights(weights + '/discriminator41000.h5')\n",
        "        msgg.G.load_weights(weights + '/generator41000.h5')\n",
        "    # start the training loop\n",
        "    msgg.train(dataset)\n",
        "\n",
        "    # make sample waveforms \n",
        "    # msgg.makewaves(dataset)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}